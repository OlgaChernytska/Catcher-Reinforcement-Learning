{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ple import PLE\n",
    "from ple.games.pixelcopter import Pixelcopter\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class NaiveAgent():\n",
    "\n",
    "    def __init__(self, actions):\n",
    "        self.actions = actions\n",
    "\n",
    "    def pickAction(self, reward, obs):\n",
    "        return self.actions[np.random.randint(0, len(self.actions))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningAgent:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.num_bins = 3\n",
    "        \n",
    "        self.boundaries = {\n",
    "            'player_vel': [-1, 1],\n",
    "            'player_dist_to_floor': [35, 40], \n",
    "            'player_dist_to_ceil': [10, 15], \n",
    "            'next_gate_dist_to_player': [5, 35]   \n",
    "        }\n",
    "            \n",
    "        \n",
    "        self.discrete_states = {\n",
    "            'player_vel': np.linspace(self.boundaries['player_vel'][0], self.boundaries['player_vel'][1], 3),\n",
    "            'player_dist_to_floor': np.linspace(self.boundaries['player_dist_to_floor'][0],\n",
    "                                                self.boundaries['player_dist_to_floor'][1], 3),\n",
    "            'player_dist_to_ceil': np.linspace(self.boundaries['player_dist_to_ceil'][0],\n",
    "                                                self.boundaries['player_dist_to_ceil'][1], 3),\n",
    "            'next_gate_dist_to_player': np.linspace(self.boundaries['player_dist_to_ceil'][0],\n",
    "                                                self.boundaries['player_dist_to_ceil'][1], 3)\n",
    "            }\n",
    "\n",
    "        self.q = self.discretize_states()\n",
    "\n",
    "    def discretize_states(self):\n",
    "        q_table = {}\n",
    "        for pv in range(len(self.discrete_states['player_vel'])+1):\n",
    "            for df in range(len(self.discrete_states['player_dist_to_floor'])+1):\n",
    "                for dc in range(len(self.discrete_states['player_dist_to_ceil'])+1):\n",
    "                    for db in range(len(self.discrete_states['next_gate_dist_to_player'])+1):\n",
    "                        for bl in range(2):\n",
    "                            q_table[hash((pv,df,dc,db,bl))] = {199: 0, None: 0, 'counter199': 0, 'counterNone': 0} \n",
    "        \n",
    "        return q_table \n",
    "    \n",
    "    def build_state(self, observation):\n",
    "        \n",
    "        player_vel = int(np.digitize(observation['player_vel'], self.discrete_states['player_vel']))\n",
    "        player_dist_to_floor = int(np.digitize(observation['player_dist_to_floor'], self.discrete_states['player_dist_to_floor']))\n",
    "        player_dist_to_ceil = int(np.digitize(observation['player_dist_to_ceil'], self.discrete_states['player_dist_to_ceil']))\n",
    "        next_gate_dist_to_player = int(np.digitize(observation['next_gate_dist_to_player'], self.discrete_states['next_gate_dist_to_player']))\n",
    "        \n",
    "        if observation['next_gate_block_bottom']>observation['next_gate_block_top']:\n",
    "            next_gate_block_loc = 1\n",
    "        else:\n",
    "            next_gate_block_loc = 0\n",
    "        \n",
    "        state = hash((player_vel, player_dist_to_floor, player_dist_to_ceil, \n",
    "                     next_gate_dist_to_player, next_gate_block_loc))\n",
    "                        \n",
    "        return state\n",
    "    \n",
    "\n",
    "    def pickAction(self, observation):\n",
    "        state = self.build_state(observation)\n",
    "        \n",
    "        #action = 199 if (dict1[8688455073536272099][199] > dict1[8688455073536272099][None]) else None\n",
    "        action = [199, None][np.random.randint(0, 2)]\n",
    "        self.q[state]['counter'+str(action)] += 1\n",
    "        \n",
    "        return action\n",
    "    \n",
    "    \n",
    "    def update_values(self, observation, reward, observation_next, action):\n",
    "\n",
    "        state = self.build_state(observation)\n",
    "        state_next = self.build_state(observation_next)\n",
    "        \n",
    "        learning_rate = 1 / self.q[state]['counter'+str(action)]\n",
    "        self.q[state][action] = self.q[state][action] + learning_rate * (reward + \n",
    "                            1*self.q[state_next][action] - self.q[state][action]) \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'player_vel': array([-1.,  0.,  1.]),\n",
       " 'player_dist_to_floor': array([35. , 37.5, 40. ]),\n",
       " 'player_dist_to_ceil': array([10. , 12.5, 15. ]),\n",
       " 'next_gate_dist_to_player': array([10. , 12.5, 15. ])}"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.discrete_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10\n",
    "\n",
    "game = Pixelcopter(width=100, height=100)\n",
    "\n",
    "p = PLE(game, fps=30, frame_skip=2, num_steps=1,\n",
    "        force_fps=False, display_screen=False)\n",
    "\n",
    "agent = LearningAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode    0 result:   6 timesteps\n",
      "Episode    1 result:   9 timesteps\n",
      "Episode    2 result:  11 timesteps\n",
      "Episode    3 result:   8 timesteps\n",
      "Episode    4 result:  10 timesteps\n",
      "Episode    5 result:   9 timesteps\n",
      "Episode    6 result:  11 timesteps\n",
      "Episode    7 result:  10 timesteps\n",
      "Episode    8 result:  10 timesteps\n",
      "Episode    9 result:  10 timesteps\n",
      "Episode   10 result:   8 timesteps\n",
      "Episode   11 result:  10 timesteps\n",
      "Episode   12 result:  11 timesteps\n",
      "Episode   13 result:   8 timesteps\n",
      "Episode   14 result:  11 timesteps\n",
      "Episode   15 result:  11 timesteps\n",
      "Episode   16 result:   9 timesteps\n",
      "Episode   17 result:   8 timesteps\n",
      "Episode   18 result:  10 timesteps\n"
     ]
    }
   ],
   "source": [
    "results = pd.DataFrame()\n",
    "actions = []\n",
    "for episode_index in range(n_episodes):\n",
    "    #print('Eposode %4d running...' % episode_index)\n",
    "    p.reset_game()\n",
    "\n",
    "        \n",
    "    for timestep_index in range(100):\n",
    "       \n",
    "        observation = game.getGameState()\n",
    "        action = agent.pickAction(observation)\n",
    "        reward = p.act(action)\n",
    "        \n",
    "        if reward < 0:\n",
    "            reward = -5\n",
    "        \n",
    "        observation_next = game.getGameState()\n",
    "        agent.update_values(observation, reward, observation_next, action)\n",
    "\n",
    "        observation['action'] = action\n",
    "        observation['reward'] = reward\n",
    "        \n",
    "        results = results.append(pd.DataFrame(observation, index=[episode_index]))\n",
    "        \n",
    "        \n",
    "        done = p.game_over() \n",
    "        if done:\n",
    "            print('Episode %4d result: %3d timesteps' % (episode_index, timestep_index))\n",
    "            break\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
